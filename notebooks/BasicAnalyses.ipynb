{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Project Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'src' directory as one where we can import modules\n",
    "import sys\n",
    "import pathlib # __file__ isn't recognized in Jupyter, so we need this to get the root path\n",
    "path = pathlib.Path.cwd()\n",
    "PROJ_ROOT = path.parent \n",
    "src_dir = str(PROJ_ROOT / 'src')\n",
    "PROJ_ROOT = str(PROJ_ROOT)\n",
    "sys.path.append(src_dir)\n",
    "from data import make_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Usernames, Confirm that the core data is up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating raw data for:\n",
      "['doyle coleman', 'pinky618', 'davidt', 'vinnov10']\n",
      "Updated raw data for users:\n",
      "['pinky618', 'vinnov10', 'davidt', 'doyle coleman']\n",
      "Updated raw data for:\n",
      "['pinky618', 'vinnov10', 'davidt', 'doyle coleman']\n",
      "Interim users_df not found, generating new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinny\\Documents\\HeyCharlie Analysis Repo\\analysis\\src\\data\\location_df_analyses.py:74: FutureWarning: 'timestamp' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  activity = user_loc_activity.sort_values('timestamp', ascending=True)\n",
      "C:\\Users\\Vinny\\Documents\\HeyCharlie Analysis Repo\\analysis\\src\\data\\location_df_analyses.py:74: FutureWarning: 'timestamp' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  activity = user_loc_activity.sort_values('timestamp', ascending=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\vinny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vinny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1970\u001b[0m             raise ValueError(\"Can only index by location with \"\n\u001b[1;32m-> 1971\u001b[1;33m                              \"a [{types}]\".format(types=self._valid_types))\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only index by location with a [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a10a68fa4217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# manual_usernames = ['+vinny']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtoday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0musernames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmanual_usernames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPROJ_ROOT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# Re-pulls raw data and refreshes basic interim data files: users_df.pkl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# and a bunch for each user: filename + username + '.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HeyCharlie Analysis Repo\\analysis\\src\\data\\make_dataset.py\u001b[0m in \u001b[0;36mrefresh_user_data\u001b[1;34m(usernames, PROJ_ROOT, max_date)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mlocations_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocations_df_setup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocations_df_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterim_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         location_df_analyses.location_df_setup(username, users_df, locations_df, raw_data_path,\n\u001b[1;32m---> 90\u001b[1;33m                                                          interim_data_path)\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Confirm update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HeyCharlie Analysis Repo\\analysis\\src\\data\\location_df_analyses.py\u001b[0m in \u001b[0;36mlocation_df_setup\u001b[1;34m(username, users_df, locations_df, raw_data_path, interim_data_path)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlocation_df_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterim_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mlocation_visits_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_interim_loc_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterim_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[0mdaily_loc_log_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_bucket_visits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation_visits_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterim_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'day'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mweekly_loc_log_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_bucket_visits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation_visits_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterim_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'week'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HeyCharlie Analysis Repo\\analysis\\src\\data\\location_df_analyses.py\u001b[0m in \u001b[0;36mcreate_interim_loc_data\u001b[1;34m(username, users_df, user_locations_df, raw_data_path, interim_data_path)\u001b[0m\n\u001b[0;32m    167\u001b[0m                         \u001b[0muser_loc_activity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'risk_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrisk_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mlocation_visits_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpull_location_visits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_loc_activity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[0minterim_data_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterim_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loc_log_df_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0musername\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mlocation_visits_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterim_data_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HeyCharlie Analysis Repo\\analysis\\src\\data\\location_df_analyses.py\u001b[0m in \u001b[0;36mpull_location_visits\u001b[1;34m(username, user_loc_activity)\u001b[0m\n\u001b[0;32m     91\u001b[0m \t\t\tfuture_events = activity[(activity.index > i)\n\u001b[0;32m     92\u001b[0m \t\t\t\t\t\t\t\t\t & (activity['locationId'] == activity.loc[i, 'locationId'])]\n\u001b[1;32m---> 93\u001b[1;33m                         \u001b[0mnext_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_timestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                                 \u001b[0mnext_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ms\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vinny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vinny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2011\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2013\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2014\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vinny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n\u001b[0;32m    225\u001b[0m                                  \u001b[1;34m\"[{types}] types\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                                  .format(types=self._valid_types))\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_nested_tuple_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
     ]
    }
   ],
   "source": [
    "manual_usernames = ['emily', '+vinny', 'jake', 'hayyogirl', 'Rabbit', 'username']\n",
    "manual_usernames = ['inreverie', 'jake', 'username', 'rabbit',\n",
    "       'hayyogirl', '+vinny', 'joeybars7', 'joeybars', 'rusty', 'upstate518',\n",
    "       'fenderman123', 'philoiz', 'ceecee', 'anonysauce', 'keirmaley',\n",
    "       'nepthys', 'plush.mary', 'jmeow', 'shanila', 'google', 'nimaghafari']\n",
    "manual_usernames = ['doyle coleman', 'pinky618', 'davidt', 'vinnov10']\n",
    "demo_username = 'vinnov10'\n",
    "# manual_usernames = ['+vinny']\n",
    "today = dt.date.today()\n",
    "usernames = make_dataset.refresh_user_data(manual_usernames, PROJ_ROOT, today)\n",
    "# Re-pulls raw data and refreshes basic interim data files: users_df.pkl \n",
    "# and a bunch for each user: filename + username + '.pkl'\n",
    "#   contacts_df_, day_comm_log_df_, week_comm_log_df_\n",
    "#   locations_df_, loc_log_df_, day_loc_log_df_, week_loc_log_df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Interested Date Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_indices = pd.date_range(today - dt.timedelta(50), today + dt.timedelta(0), freq='W-MON')\n",
    "print(date_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Establish interim data path, open some data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import user_df_setup\n",
    "\n",
    "interim_data_file_path = os.path.join(PROJ_ROOT,\n",
    "                                 \"data\",\n",
    "                                 \"interim\",\n",
    "                                 \"full_users_df.pkl\")\n",
    "raw_data_file_path = os.path.join(PROJ_ROOT,\n",
    "                                 \"data\",\n",
    "                                 \"raw\",\n",
    "                                 \"users_df.pkl\")\n",
    "users_df = user_df_setup.user_df_setup(raw_data_file_path, interim_data_file_path)\n",
    "# users_df = pd.read_pickle(interim_data_file_path)\n",
    "raw_users_df = pd.read_pickle(raw_data_file_path)\n",
    "\n",
    "# raw_users_df\n",
    "# raw_users_df[['username', 'timeCreated']].sort_values('timeCreated', ascending = False).head(20)\n",
    "# all_users_df.sort_values('date_created', ascending = False).head(20)\n",
    "# all_users_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pulling communication, location data into user dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_data_path = os.path.join(PROJ_ROOT,\n",
    "                                 \"data\",\n",
    "                                 \"interim\")\n",
    "raw_data_file_path = os.path.join(PROJ_ROOT,\n",
    "                                 \"data\",\n",
    "                                 \"raw\")\n",
    "daily_comm_dict = {}\n",
    "weekly_comm_dict = {}\n",
    "contacts_dict = {}\n",
    "\n",
    "weekly_loc_log_dict = {}\n",
    "locations_dict = {}\n",
    "\n",
    "for username in usernames:\n",
    "    daily_comm_df, weekly_comm_df, weekly_loc_log_df, locations_df = np.nan, np.nan, np.nan, np.nan\n",
    "    interim_comm_data_file_path = os.path.join(interim_data_path, 'week_comm_log_df_' + username + '.pkl')\n",
    "    if os.path.isfile(interim_comm_data_file_path):\n",
    "        weekly_comm_df = pd.read_pickle(interim_comm_data_file_path)\n",
    "        weekly_comm_dict[username] = weekly_comm_df\n",
    "        \n",
    "    interim_comm_data_file_path = os.path.join(interim_data_path, 'day_comm_log_df_' + username + '.pkl')\n",
    "    if os.path.isfile(interim_comm_data_file_path):\n",
    "        daily_comm_df = pd.read_pickle(interim_comm_data_file_path)\n",
    "        daily_comm_dict[username] = daily_comm_df\n",
    "    \n",
    "    interim_contact_data_file_path = os.path.join(interim_data_path, 'contacts_df_' + username + '.pkl')\n",
    "    contacts_df = pd.read_pickle(interim_contact_data_file_path)\n",
    "    contacts_dict[username] = contacts_df\n",
    "    \n",
    "    interim_loc_data_file_path = os.path.join(interim_data_path, 'week_loc_log_df_' + username + '.pkl')\n",
    "    if os.path.isfile(interim_loc_data_file_path):\n",
    "        weekly_loc_log_df = pd.read_pickle(interim_loc_data_file_path)\n",
    "        weekly_loc_log_dict[username] = weekly_loc_log_df\n",
    "    \n",
    "    locations_data_file_path = os.path.join(interim_data_path, 'locations_df_' + username + '.pkl')\n",
    "    locations_df = pd.read_pickle(locations_data_file_path)\n",
    "    locations_dict[username] = locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly_loc_log_dict['pinky618']\n",
    "# weekly_comm_dict[usernames[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pulling notifictaion dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# notification_dict = make_dataset.make_notification_data(users_df, usernames, PROJ_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import generate_report_charts\n",
    "\n",
    "chart_path = os.path.join(PROJ_ROOT,\n",
    "                          \"notebooks\",\n",
    "                          \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_days_line_chart_cols = ['total_comm_days', 'risky_comm_days', 'supportive_comm_days']\n",
    "\n",
    "for username in usernames:\n",
    "    print(username)\n",
    "    comm_days_line_chart_data = weekly_comm_dict[username][comm_days_line_chart_cols]\n",
    "    comm_days_line_chart_data = comm_days_line_chart_data[min(date_indices):max(date_indices)]\n",
    "    comm_days_line_chart_data = comm_days_line_chart_data[(comm_days_line_chart_data.index >= date_indices[0])]\n",
    "#     comm_days_line_chart_data = comm_days_line_chart_data[(comm_days_line_chart_data.index >= date_indices[0]) & (comm_days_line_chart_data.index <= date_indices[-1])]\n",
    "#     [comm_days_line_chart_data.index >= date_indices[0]]\n",
    "    generate_report_charts.comm_days_line_chart([username], date_indices, comm_days_line_chart_data, chart_path, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(comm_days_line_chart_data[(comm_days_line_chart_data.index >= min(date_indices))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_vol_bar_chart_cols = ['total_comm', 'risky_comm', 'neutral_comm', 'supportive_comm', 'unrated_comm']\n",
    "\n",
    "for username in usernames:\n",
    "    print(username)\n",
    "    comm_vol_bar_chart_data = weekly_comm_dict[username][comm_vol_bar_chart_cols]\n",
    "#     print(comm_vol_bar_chart_data[comm_vol_bar_chart_data.index >= date_indices[0]])\n",
    "    comm_vol_bar_chart_data = comm_vol_bar_chart_data[(comm_vol_bar_chart_data.index >= date_indices[0]) & (comm_vol_bar_chart_data.index <= date_indices[-1])]\n",
    "    generate_report_charts.comm_vol_bar_chart([username], date_indices, comm_vol_bar_chart_data, chart_path, show=True)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_vol_bar_chart_cols = ['total_comm', 'risky_comm', 'neutral_comm', 'supportive_comm', 'unrated_comm']\n",
    "daily_date_indices = pd.date_range(date_indices[0], date_indices[-1], freq='D')\n",
    "for username in usernames:\n",
    "    print(username)\n",
    "    comm_vol_bar_chart_data = daily_comm_dict[username][comm_vol_bar_chart_cols]\n",
    "#     print(comm_vol_bar_chart_data[comm_vol_bar_chart_data.index >= date_indices[0]])\n",
    "    comm_vol_bar_chart_data = comm_vol_bar_chart_data[(comm_vol_bar_chart_data.index >= date_indices[0]) & (comm_vol_bar_chart_data.index <= date_indices[-1])]\n",
    "    generate_report_charts.comm_vol_bar_chart([username], daily_date_indices, comm_vol_bar_chart_data, chart_path, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comm_pie_chart_cols = ['risky_percent', 'neutral_percent', 'supportive_percent', 'unrated_percent']\n",
    "for username in usernames:\n",
    "    print(username)\n",
    "    comm_pie_chart_data = weekly_comm_dict[username][comm_pie_chart_cols]\n",
    "#     print(comm_pie_chart_data)\n",
    "#     print(comm_pie_chart_data.index)\n",
    "#     print(date_indices)\n",
    "#     print(date_indices[-1].date() - dt.timedelta(7))\n",
    "#     print(comm_pie_chart_data.loc[date_indices[-2].date()])\n",
    "    if date_indices[-2] in comm_pie_chart_data.index:\n",
    "        generate_report_charts.comm_pie_chart([username], date_indices[-2], comm_pie_chart_data.loc[date_indices[-2]], chart_path, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_dict = {}\n",
    "for username in usernames: \n",
    "    raw_locations_file_path = os.path.join(PROJ_ROOT,\n",
    "                             \"data\",\n",
    "                             \"raw\",\n",
    "                             'locations_df_' + username + '.pkl')\n",
    "    if os.path.isfile(raw_locations_file_path):\n",
    "        locations_df = pd.read_pickle(raw_locations_file_path)\n",
    "    locations_dict[username] = locations_df\n",
    "# locations_dict[demo_username].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Location Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loc_days_bar_chart_cols = ['days_w_risky_loc_visits']\n",
    "\n",
    "for username in usernames:\n",
    "    print(username)\n",
    "    loc_days_bar_chart_data = weekly_loc_log_dict[username][loc_days_bar_chart_cols]\n",
    "#     print(comm_vol_bar_chart_data[comm_vol_bar_chart_data.index >= date_indices[0]])\n",
    "    loc_days_bar_chart_data = loc_days_bar_chart_data[(loc_days_bar_chart_data.index >= date_indices[0]) & (loc_days_bar_chart_data.index <= date_indices[-1])]\n",
    "    generate_report_charts.loc_days_bar_chart([username], date_indices, loc_days_bar_chart_data, chart_path, show=True)\n",
    "# loc_days_bar_chart_cols = ['days_w_risky_loc_visits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# users_df.head\n",
    "# contacts_dict['+vinny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, axarr = plt.subplots(len(usernames),figsize=(10,4*len(usernames)), sharex = True, sharey = True, squeeze=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "for count, e in enumerate(usernames):  \n",
    "    unrated_threshold = users_df.loc[e, 'unrated_threshold']\n",
    "    risky_threshold = users_df.loc[e, 'risky_threshold']\n",
    "    supportive_threshold = users_df.loc[e, 'supportive_threshold']\n",
    "    \n",
    "    contacts_df = contacts_dict[e].sort_values('score', ascending = False)\n",
    "    unrated = contacts_df['score'][(contacts_df['score'] < unrated_threshold)\n",
    "                                  & (contacts_df['relationship'] != 'risky')]\n",
    "    risky = contacts_df['score'][(contacts_df['relationship'] == 'risky')\n",
    "                                | ((contacts_df['score'] >= unrated_threshold)\n",
    "                                & (contacts_df['score'] <= risky_threshold))]\n",
    "    neutral = contacts_df['score'][(contacts_df['score'] > risky_threshold)\n",
    "                                & (contacts_df['score'] < supportive_threshold)]\n",
    "    supportive = contacts_df['score'][(contacts_df['score'] >= supportive_threshold)]\n",
    "    \n",
    "    axarr[count, 0].bar(supportive.index, supportive, 0.7, color = '#00cc00')\n",
    "    axarr[count, 0].bar(neutral.index, neutral, 0.7, color = 'b')\n",
    "    axarr[count, 0].bar(risky.index, risky, 0.7, color = '#ff6600')\n",
    "#     axarr[count].bar(unrated.index, unrated, 0.7, color = '#C0C0C0')\n",
    "    axarr[count, 0].set_title(e + ' - rated: ' + str(len(contacts_df) - len(unrated)) + ' unrated: ' + str(len(unrated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_comm_dict['davidt'][comm_days_line_chart_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "activity = weekly_comm_dict['davidt'][comm_days_line_chart_cols]\n",
    "# print(activity.index)\n",
    "for i in activity.index:\n",
    "    print(activity.loc[i])\n",
    "    print(activity[activity.index > i])\n",
    "#     print(activity.loc[(i+1):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "activity = weekly_comm_dict['davidt'][comm_days_line_chart_cols]\n",
    "# print(activity.index)\n",
    "for i in range(len(activity.index)):\n",
    "    print(activity.iloc[i])\n",
    "    print(activity.iloc[(i+1):])\n",
    "#     idx = np.searchsorted(df.index, cur_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
